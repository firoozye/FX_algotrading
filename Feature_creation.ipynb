{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d6ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import multiprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import kaleido\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "from scipy.linalg import pinv\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.dates as mdates\n",
    "from joblib import Parallel, delayed\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e84f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AdaptiveBenignOverfitting import *\n",
    "from forecast_utils import *\n",
    "from backtesting_utils import *\n",
    "from features.feature_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd0fb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b7c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('~/Dropbox/FX/GBPUSD_df_daily.xlsx')\n",
    "df.set_index('Date',inplace = True)\n",
    "df['GBPUSD_SPREAD'] = df['GBPUSD_PX_ASK'] - df['GBPUSD_PX_BID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "516b8d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AR_MA_features(df_old, columns, window_sizes):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df.index = df_old.index\n",
    "    \"\"\"\n",
    "    Adds financial features to the DataFrame for specified columns and multiple window sizes.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The original DataFrame.\n",
    "    columns (list): List of column names to calculate features for.\n",
    "    window_sizes (list): List of window sizes for calculating SMA, EMA, and rolling std.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The original DataFrame with added financial features.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        # Calculate returns\n",
    "        df[f'{col}_returns'] = df_old[col].pct_change()\n",
    "        for window_size in window_sizes:\n",
    "            # SMA of returns\n",
    "            df[f'{col}_sma_{window_size}'] = df[f'{col}_returns'].rolling(window=window_size).mean()\n",
    "\n",
    "            # EMA of returns\n",
    "            df[f'{col}_ema_{window_size}'] = df[f'{col}_returns'].ewm(span=window_size, adjust=False).mean()\n",
    "\n",
    "            # Lagged Returns\n",
    "            df[f'{col}_AR_{window_size}'] = df[f'{col}_returns'].shift(window_size)\n",
    "\n",
    "            # Rolling Standard Deviation\n",
    "            df[f'{col}_rolling_std_{window_size}'] = df[f'{col}_returns'].rolling(window=window_size).std()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01353d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_surprise(df):\n",
    "\n",
    "    eco_index_cols = [col for col in df.columns if '_ACTUAL_RELEASE' in col]\n",
    "    prefixes = [col.split('_ACTUAL_RELEASE')[0] for col in eco_index_cols]\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    for prefix in prefixes:\n",
    "        act_col = f\"{prefix}_ACTUAL_RELEASE\"\n",
    "        est_col = f\"{prefix}_SURVEY_AVERAGE\"\n",
    "        std_col = f\"{prefix}_FORECAST_STANDARD_DEVIATION\"\n",
    "        high_col = f\"{prefix}_SURVEY_HIGH\"\n",
    "        low_col = f\"{prefix}_SURVEY_LOW\"\n",
    "        surp_col = f\"{prefix}_SURP\"\n",
    "\n",
    "\n",
    "        df[surp_col] = (df[act_col] - df[est_col])/np.where(df[std_col]==0,(df[high_col]-df[low_col])/4,df[std_col])\n",
    "        df[surp_col].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        df[surp_col].fillna(0,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94109fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_technicals(df, window_sizes):\n",
    "\n",
    "    technicals_df = pd.DataFrame()\n",
    "    technicals_df.index = df.index\n",
    "    close_prices = df['GBPUSD_PX_LAST']\n",
    "    high_prices = df['GBPUSD_PX_HIGH']\n",
    "    low_prices = df['GBPUSD_PX_LOW']\n",
    "    \n",
    "    for i in window_sizes:\n",
    "        colname = 'RSI_' + str(i)\n",
    "        technicals_df[colname] = RSIIndicator(close=close_prices, window =i).rsi()\n",
    "       \n",
    "    for i in window_sizes:\n",
    "        colname = 'oscillator_' + str(i)\n",
    "        technicals_df[colname] = 100*((close_prices - low_prices.rolling(window = i).min()) / (high_prices.rolling(window = i).min() - low_prices.rolling(window = i).min()))\n",
    "    \n",
    "    for i in window_sizes: \n",
    "        colname = 'adx_' + str(i)\n",
    "        adxI = ADXIndicator(high=high_prices, low=low_prices, close=close_prices, window=i)\n",
    "        technicals_df[colname] = adxI.adx()\n",
    "    return technicals_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f67c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['SPX_PX_MID','UKX_PX_MID','GBPUSD_PX_LAST',\n",
    "           'GBPUSD_PX_LOW','GBPUSD_PX_HIGH',\n",
    "           'GBPUSD_SPREAD','GBPUSD_BASIS_1W','GBPUSD_BASIS_1M',\n",
    "           'GBPUSD_FRD_1W','GBPUSD_FRD_1M',\n",
    "           'USD_BOND_3M','GBP_BOND_1Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c76cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [5,6,8,10,12,15,16,20,30,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f722f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ARMA = get_AR_MA_features(df,columns, window_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e20545c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_technicals = get_technicals(df,window_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cb2b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = pd.merge(df_technicals, df_ARMA, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c92c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_index_cols = [col for col in df.columns if '_ACTUAL_RELEASE' in col]\n",
    "prefixes = [col.split('_ACTUAL_RELEASE')[0] for col in eco_index_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85b6d65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_columns = [col for col in df.columns if any(s in col for s in prefixes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c656b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro = pd.DataFrame()\n",
    "df_macro[macro_columns] = df[macro_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17ff5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro = calc_surprise(df_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8282da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = pd.merge(df_feature, df_macro, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e704aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature['close'] = df['GBPUSD_PX_LAST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daeb5db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv_cols = ['GBPUSD_VOLA_1W','GBPUSD_VOLA_1M','GBPUSD_SKEW_1W','GBPUSD_SKEW_1M',\n",
    "             'GBPUSD_KURT_1W','GBPUSD_KURT_1M']\n",
    "df_feature[deriv_cols] = df[deriv_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5fe82ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41b43e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e5c21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35de5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest = df_perf['binary']*df_perf['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55657987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8834a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2 = backtest.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022eee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array_eps = (df_perf['signal_large']*df_perf['target']).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe93907",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((1+array)*100000, label = 'Expanding window + ff')\n",
    "plt.plot((1+array_2)*100000, label = 'Rolling window')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657751e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_perf['Close'])\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6673c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33cd9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a749b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_index_df_past = df_past.index[-1:]\n",
    "indices_df_future = df_future.index[:-1]\n",
    "combined_indices = last_index_df_past.append(indices_df_future)\n",
    "results_df = pd.DataFrame(index=combined_indices)\n",
    "results_df['actual'] = np.nan\n",
    "results_df['mean'] = np.nan\n",
    "\n",
    "# Initialize the neccesary lists\n",
    "models = []\n",
    "bags = []\n",
    "all_bags_array = []\n",
    "betas_array = []\n",
    "# Select the most recent data from the available dataframe\n",
    "df_model = df_past[-(roll_size+1):] # size is roll_size + 1, because we need 1 more point to make prediction\n",
    "                                    # for that point we don't know the target variable yet\n",
    "\n",
    "# calculate targets and scale the data\n",
    "Y, X, scaler_Y, scaler_X = prepare_data(df_model) \n",
    "\n",
    "# perform RFF transformation\n",
    "lags = X.shape[0]\n",
    "rff = GaussianRFF(lags, D, sigma)\n",
    "X_trans = rff.transform(X.reshape(lags, roll_size+1)).T\n",
    "\n",
    "#Sampling features in each bag\n",
    "features_array = sample_features(D,n_bags,feature_num)\n",
    "\n",
    "for p in range(n_bags):\n",
    "    bags.append(X_trans[:,features_array[p]])\n",
    "\n",
    "# Parallel execution of the first loop. Model initialization\n",
    "results = Parallel(n_jobs=-1)(delayed(process_initial_bag)(p, bags, Y, scaler_Y, ff, l, feature_num, roll_size, exp_window) for p in tqdm(range(0, n_bags)))\n",
    "all_bags_preds = np.array([result[0] for result in results])\n",
    "models = [result[1] for result in results]\n",
    "betas = np.array([result[2] for result in results])\n",
    "betas_array.append(betas)\n",
    "all_bags_array.append(np.array(all_bags_preds).T)\n",
    "#Add results in a results dataframe for comparison\n",
    "results_df['actual'].iloc[0] = df_future['close'][0]/df_past['close'][-1]-1 #actual target\n",
    "results_df['mean'].iloc[0] = np.mean(all_bags_preds)\n",
    "\n",
    "#Continue performing forecasts by updating QR_RLS model\n",
    "df_temp = df_model\n",
    "\n",
    "# we need the last row of RFF dataset to append it to train set on next iteration\n",
    "X_old = X_trans[-1,:].T  \n",
    "\n",
    "for i in tqdm(range(0, 300)):\n",
    "    \n",
    "    #Delete old data and append data, that just became available\n",
    "    df_temp = df_temp.iloc[1:]\n",
    "    df_temp = df_temp.append(df_future.iloc[i])\n",
    "    \n",
    "    Y, X, scaler_Y, scaler_X = prepare_data(df_temp)\n",
    "    \n",
    "    ## We need to perform RFF expansion on the new observation row. For which we don't have target\n",
    "    ## And which will be used for forecasting\n",
    "    X_new = rff.transform(X[:, -1:].reshape(lags, 1))\n",
    "    \n",
    "    # Parallel execution of the second loop\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_updated_bag)(p, X_old, X_new, models, scaler_Y, Y, features_array, feature_num) for p in range(0, n_bags))\n",
    "    all_bags_preds = np.array([result[0] for result in results])\n",
    "    betas = [result[1] for result in results]\n",
    "    betas_array.append(betas)\n",
    "    all_bags_array.append(np.array(all_bags_preds).T)\n",
    "    #new obeservation will be appended to train set in the next iteration\n",
    "    X_old = X_new \n",
    "    \n",
    "    # record results\n",
    "    results_df['actual'].iloc[i+1] = df_future['close'][i+1]/df_temp['close'][-1]-1 #actual target\n",
    "    results_df['mean'].iloc[i+1] = np.mean(all_bags_preds)\n",
    "    \n",
    "    ##CHANGE-POINT test here\n",
    "    \n",
    "    \n",
    "    \n",
    "    if i % 10 == 0 and i > 0:\n",
    "        \n",
    "        same_sign_count = ((results_df['mean'][:i] > 0) & (results_df['actual'][:i] > 0)).sum() + ((results_df['mean'][:i] < 0) & (results_df['actual'][:i] < 0)).sum()\n",
    "\n",
    "        # Calculate the percentage\n",
    "        total_rows = len(results_df['mean'][:i])\n",
    "        percentage_same_sign = (same_sign_count / total_rows) * 100\n",
    "\n",
    "        print(f\"Accuracy on iteration {i}: {percentage_same_sign:.2f}%\")\n",
    "        \n",
    "        p = results_df['mean'][:i].corr(results_df['actual'][:i])\n",
    "\n",
    "\n",
    "\n",
    "        # Calculate rolling Sharpe ratio\n",
    "        if not np.isnan(p):  # Check if p is not NaN\n",
    "            rolling_sharpe_ratio = (p / np.sqrt(p**2 + 1)) * np.sqrt(252)\n",
    "            print(f\"Accuracy on iteration {i}: {percentage_same_sign:.2f}%, Rolling Sharpe Ratio: {rolling_sharpe_ratio:.2f}\")\n",
    "        else:\n",
    "            print(f\"Accuracy on iteration {i}: {percentage_same_sign:.2f}%, Rolling Sharpe Ratio: Cannot be calculated (NaN)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
